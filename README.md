# Portfolio-Projects-Data-Science
![Alt Text](https://media.giphy.com/media/DS89v1NqpzCqA/giphy.gif)
## Project 1. COVID-19 Analysis (Using SQL and Tableau BI)
This is a COVID-19 Analysis project that provides an analysis of the COVID-19 pandemic using SQL. The project utilizes SQL queries and CTE's to analyze and visualize various aspects of the pandemic, including the spread of the virus, it's impact on different populations, and trends over time. The project includes SQL scripts, the data, and documentation to support reproducibility and transparency. Please check this link for Viz. on Tableau : https://public.tableau.com/app/profile/ramandeep.bhatia/viz/CovidCasesDashboard_16581942656400/Dashboard3
- Project Overview
- Data Sources
- Datail Analysis
### Project Overview
The COVID-19 Analysis project aims to provide insights into the ongoing pandemic by analyzing data related to the spread and impact of the COVID-19 virus using SQL. The project uses SQL as the primary query language to query and analyze data from various sources, including global and regional COVID-19 datasets, population demographics, and other relevant data.

### The project is organized into several main components:
- Data collection and preprocessing: The project includes SQL scripts to collect and preprocess data from various sources, including global and regional COVID-19 datasets, population demographics, and other relevant data.
- Data analysis: The project includes SQL queries that perform analysis on the collected data to uncover patterns, trends, and insights related to COVID-19.
- Documentation: The project includes detailed documentation on the project structure, data sources, methodology, and findings to ensure transparency and reproducibility.
### Data Sources 
- The COVID-19 Analysis project uses data from various sources, including public datasets, APIs, and official COVID-19 data repositories. The data sources used in this project include:
- Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE) COVID-19 Data Repository: This dataset provides daily updated data on confirmed cases, deaths, and recoveries at the global, country, and regional levels.
- World Bank Open Data: This dataset provides socio-economic and demographic data that can be used to analyze the impact of COVID-19 on different populations and regions.

### Analysis
- The COVID-19 Analysis project includes various SQL queries for analysis, such as:
- Querying COVID-19 cases, deaths, and recoveries at the global, country, and regional levels.
- Performing aggregations, joins, and filtering to identify trends and patterns in COVID-19 data.
- Calculating summary statistics and generating visualizations using SQL.
- Conducting time-series analysis and trend analysis using SQL.

## Project 2. Correlation between Budget and Gross Earnings of Movies Using Python
- This is a Python project that explores the relationship between the budget and gross earnings of movies using Kaggle Movies Data. The project utilizes Python libraries such as Pandas, Matplotlib, and NumPy for data manipulation, visualization, and analysis.
### Project Description
The main objective of this project is to analyze the correlation between the budget and gross earnings of movies using the Kaggle Movies Data. The dataset contains information about various movies, including their budgets, gross earnings, and other relevant details. The project includes the following steps:
- Data Loading and Preprocessing: The Kaggle Movies Data is loaded into a Pandas DataFrame, and necessary preprocessing steps are performed, such as handling missing values, converting data types, and filtering relevant columns.
-Correlation Calculation: The project uses the Pandas corr() method to calculate the Pearson correlation coefficient between the budget and gross earnings columns in the DataFrame. The Pearson correlation coefficient is a measure of the linear relationship between two variables, with values ranging from -1 to 1. A positive value indicates a positive correlation, while a negative value indicates a negative correlation.
- Correlation Matrix: The project also includes code to create a correlation matrix using the Pandas corr() method. The correlation matrix is a matrix that shows the correlation coefficients between multiple pairs of variables in a DataFrame. It provides a comprehensive overview of the correlations between different variables in the dataset, allowing for a deeper analysis of the relationships.
- Correlation Analysis: The project interprets the calculated correlation coefficient and correlation matrix in terms of the strength and direction of the relationship between the budget and gross earnings of movies. It discusses whether the variables have a strong or weak correlation, and whether the relationship is positive or negative.
- Visualization: The project uses Matplotlib, a popular data visualization library in Python, to create scatter plots and other types of plots that visualize the relationship between the budget and gross earnings of movies. These visualizations provide insights into the correlation between the variables and help in better understanding the data.
### The Python libraries used:
- Pandas
- Matplotlib
- NumPy
### Acknowledgements
This project uses the Kaggle Movies Data, which is a publicly available dataset. The dataset can be found at the following link: https://www.kaggle.com/rounakbanik/the-movies-dataset

## Project 3. Housing Data Cleaning Project
- This project involved cleaning housing data using SQL to remove errors, duplicates, missing values, structural errors, and inaccuracies. The dataset contains information about various properties, such as property type, location, price, size, and other relevant details.

### Goals
The main goals of this project were:
- Identifying and correcting errors in the housing data, including incorrect values, inconsistent formatting, and invalid entries.
- Identifying and removing duplicate entries, ensuring that each property is represented only once in the cleaned dataset.
- Handling missing values by either imputing them based on appropriate methods or removing rows with missing data, as applicable.
- Addressing structural errors, such as inconsistencies in data types, formats, or units across different columns or tables.
- Identifying and correcting inaccuracies in the housing data, such as outliers or data entry mistakes, to ensure the accuracy and reliability of the dataset.
### Methodology
The following steps I have followed to clean the housing data using SQL:
- Data Assessment: Conducting a thorough assessment of the dataset to identify errors, duplicates, missing values, structural errors, and inaccuracies.
- Data Cleaning: Using SQL queries to correct errors, remove duplicates, handle missing values, address structural errors, and correct inaccuracies in the housing data.
- Data Validation: Validating the cleaned dataset to ensure that it meets the quality and accuracy requirements of the project.
- Documentation: Creating documentation that outlines the steps taken in the data cleaning process, the decisions made, and the results obtained, to facilitate reproducibility and future reference.
### Deliverables
The final deliverables of this project was:
- A cleaned and validated housing dataset in SQL format, free from errors, duplicates, missing values, structural errors, and inaccuracies.
- Documentation summarizing the data cleaning process, including the steps taken, decisions made, and results obtained, for future reference.
Any additional insights or recommendations based on the findings during the data cleaning process.
Conclusion
- The housing data cleaning project using SQL aims to ensure that the dataset is accurate, reliable, and ready for further analysis or modeling. By addressing errors, duplicates, missing values, structural errors, and inaccuracies in the data, this project will result in a cleaned dataset that can be used for various purposes, such as statistical analysis, predictive modeling, or data visualization.
